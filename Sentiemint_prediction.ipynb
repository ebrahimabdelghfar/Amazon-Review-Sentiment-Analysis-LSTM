{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Get the The library for the sentiment analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Intiate objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=tf.keras.models\n",
    "layers=tf.keras.layers\n",
    "preprocessing=tf.keras.preprocessing\n",
    "pading=tf.keras.preprocessing.sequence\n",
    "uility=tf.keras.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load and Clean the data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=open('train.ft.txt',encoding=\"utf8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[int(i[0:11].replace(\"__label__\",\"\")) for i in train_text]\n",
    "input_text=[i[11:] for i in train_text]\n",
    "\n",
    "# as the data is huge we are taking only 10000 samples\n",
    "label=label[:10000]\n",
    "input_text=input_text[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  2\n"
     ]
    }
   ],
   "source": [
    "num_of_classes=len(set(label))\n",
    "print(\"Number of classes: \",num_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    text=re.sub(r'\\d+','',text)\n",
    "    text=text.lower()\n",
    "    text=[word for word in text.split() if word not in stopwords.words(\"english\")]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    text=[lemmatizer.lemmatize(word) for word in text]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "\n",
    "cleaned_input_text=[clean_text(i) for i in input_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuning even nongamer sound track beautiful paint senery mind well would recomend even people hate vid game music played game chrono cross game ever played best music back away crude keyboarding take fresher step grate guitar soulful orchestra would impress anyone care listen _'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=preprocessing.text.Tokenizer()\n",
    "#prepare the data for training\n",
    "def prepare(input_data:list)->list:\n",
    "    input_sequences=[]\n",
    "    tokenizer.fit_on_texts(input_data)\n",
    "    for i in input_text:\n",
    "        token_list=tokenizer.texts_to_sequences([i])[0]\n",
    "        input_sequences.append(token_list)\n",
    "    max_len=max([len(x) for x in input_sequences])\n",
    "    input_sequences=pading.pad_sequences(input_sequences,maxlen=max_len,padding=\"pre\")\n",
    "    return input_sequences,len(tokenizer.word_index)#number of unique words in the text\n",
    "\n",
    "\n",
    "input_data,voc=prepare(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(label)):\n",
    "    if label[i]==2:\n",
    "        label[i]=1\n",
    "    else:\n",
    "        label[i]=0\n",
    "    \n",
    "labels=uility.to_categorical(y=label,num_classes=num_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create and train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 215, 100)          3347000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 215, 150)          150600    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 215, 150)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,598,202\n",
      "Trainable params: 3,598,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_len=max([len(x) for x in input_data])\n",
    "model=models.Sequential()\n",
    "model.add(layers.Embedding(input_dim=voc+1,output_dim=100,input_length=max_len))\n",
    "model.add(layers.LSTM(150,return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(100))\n",
    "model.add(layers.Dense(num_of_classes,activation='softmax'))#dense layer with softmax activation as we have to predict the next word\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 124s 244ms/step - loss: 0.5061 - accuracy: 0.7554 - val_loss: 0.4376 - val_accuracy: 0.8040\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 155s 310ms/step - loss: 0.2284 - accuracy: 0.9160 - val_loss: 0.4034 - val_accuracy: 0.8430\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 163s 326ms/step - loss: 0.0936 - accuracy: 0.9697 - val_loss: 0.5230 - val_accuracy: 0.8330\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 163s 327ms/step - loss: 0.0553 - accuracy: 0.9825 - val_loss: 0.7201 - val_accuracy: 0.8225\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 144s 288ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.5778 - val_accuracy: 0.8045\n"
     ]
    }
   ],
   "source": [
    "history=model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model.fit(input_data,labels,epochs=5,verbose=1,batch_size=16,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bad text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "model.save('sentiment.h5')\n",
    "text='this a very bad product i have ever seen, i will never buy this product again'\n",
    "\n",
    "text=clean_text(text)\n",
    "token_list=tokenizer.texts_to_sequences([text])[0]\n",
    "token_list=pading.pad_sequences([token_list],maxlen=max_len,padding=\"pre\")\n",
    "pred=model.predict(token_list,verbose=0)\n",
    "np.argmax(pred)\n",
    "if np.argmax(pred)==0:\n",
    "    print(\"negative\")\n",
    "elif np.argmax(pred)==1:\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## good text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "text='this a very good product i have ever seen, i will buy this product again'\n",
    "\n",
    "text=clean_text(text)\n",
    "token_list=tokenizer.texts_to_sequences([text])[0]\n",
    "token_list=pading.pad_sequences([token_list],maxlen=max_len,padding=\"pre\")\n",
    "pred=model.predict(token_list,verbose=0)\n",
    "np.argmax(pred)\n",
    "if np.argmax(pred)==0:\n",
    "    print(\"negative\")\n",
    "elif np.argmax(pred)==1:\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
